{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(\"../\")\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from scripts.wiki import Wiki,Revision\n",
    "from sklearn.metrics import  silhouette_score, silhouette_samples\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vecs(wiki_vec, vocab, tokens):\n",
    "    in_vocab_tokens = set(tokens) & vocab\n",
    "    if in_vocab_tokens:\n",
    "#         return wiki_vec[in_vocab_tokens].sum(axis=0, keepdims=True) / len(in_vocab_tokens) \n",
    "        return np.average(wiki_vec[in_vocab_tokens], axis=0)\n",
    "\n",
    "\n",
    "    else:\n",
    "        return np.zeros( wiki_vec.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### reading the change object and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "article_name = \"Truth\"\n",
    "change_object_dir =  \"../data/change objects/\"\n",
    "filename = article_name + \".pkl\"\n",
    "filepath = os.path.join(change_object_dir, filename)\n",
    "if os.path.exists(filepath):\n",
    "    with open(filepath, \"rb\") as file:\n",
    "        wiki = pickle.load(file)\n",
    "else:\n",
    "    print(\"file do not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "change_objects = []\n",
    "wiki.revisions.iloc[:-1].apply(lambda revision: change_objects.append(revision.neighbour))\n",
    "change_index = [ rev.id for rev in  wiki.revisions[1:].tolist()]\n",
    "change_df = pd.concat(change_objects, sort=False, keys=change_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_s = pd.to_datetime([ rev.timestamp for rev in  wiki.revisions.values.ravel().tolist()])\n",
    "time_gap = pd.to_timedelta(timestamp_s[1:]-timestamp_s[:-1])\n",
    "editor_s = [ rev.id for rev in  wiki.revisions.tolist()]\n",
    "index = list(zip(*[timestamp_s.tolist()[1:], time_gap, editor_s[1:]]))\n",
    "# change_df = pd.concat(change_objects, sort=False, keys=index, names=[\"timestamp\", \"timegap\", \"editor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(change_objects)):\n",
    "#     change_objects[i][\"timestamp\"] = timestamp_s[i+1]\n",
    "#     change_objects[i][\"time_gap\"] = time_gap[i]\n",
    "#     change_objects[i][\"editor_s\"] = editor_s[i+1]\n",
    "# change_df = pd.concat(change_objects, sort=False, keys=wiki.revisions[:-1].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make left, ins and delete string for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_df[\"left_string\"] = change_df[\"left_token\"].str.join(\" \")\n",
    "change_df[\"ins_string\"] = change_df[\"ins_tokens\"].str.join(\" \")\n",
    "change_df[\"del_string\"] = change_df[\"del_tokens\"].str.join(\" \")\n",
    "change_df[\"right_string\"] = change_df[\"right_token\"].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_df[\"ins_token_len\"]=change_df[\"ins_tokens\"].str.len()\n",
    "change_df[\"del_token_len\"]=change_df[\"del_tokens\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Vector from change object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "wiki_vec = KeyedVectors.load_word2vec_format('../../wordvectors/wiki.en.vec', binary=False, limit=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(wiki_vec.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ins_vec_list = []\n",
    "change_df[\"ins_tokens\"].apply(lambda token_set: ins_vec_list.append(get_word_vecs(wiki_vec, vocab, token_set)))\n",
    "ins_matrix = np.c_[ins_vec_list]\n",
    "\n",
    "del_vec_list = []\n",
    "change_df[\"del_tokens\"].apply(lambda token_set: del_vec_list.append(get_word_vecs(wiki_vec, vocab, token_set)))\n",
    "del_matrix = np.c_[del_vec_list]\n",
    "ins_del_sum_matrix = (ins_matrix + del_matrix)/2\n",
    "\n",
    "del ins_vec_list\n",
    "del del_vec_list\n",
    "del ins_matrix\n",
    "del del_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "left_vec_list = []\n",
    "change_df[\"left_token\"].apply(lambda token_set: left_vec_list.append(get_word_vecs(wiki_vec, vocab, token_set[-10:])))\n",
    "left_neighbour_matrix = np.c_[left_vec_list]\n",
    "\n",
    "right_vec_list = []\n",
    "change_df[\"right_token\"].apply(lambda token_set: right_vec_list.append(get_word_vecs(wiki_vec, vocab, token_set[:10])))\n",
    "right_neighbour_matrix = np.c_[right_vec_list]\n",
    "\n",
    "neighbour_10_matrix = np.concatenate([ left_neighbour_matrix, right_neighbour_matrix], axis=1)\n",
    "\n",
    "ins_del_10_sum_neighbour_matrix = np.concatenate([left_neighbour_matrix, ins_del_sum_matrix, right_neighbour_matrix], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "left_vec_list = []\n",
    "change_df[\"left_token\"].apply(lambda token_set: left_vec_list.append(get_word_vecs(wiki_vec, vocab, token_set[-4:])))\n",
    "left_neighbour_matrix = np.c_[left_vec_list]\n",
    "\n",
    "right_vec_list = []\n",
    "change_df[\"right_token\"].apply(lambda token_set: right_vec_list.append(get_word_vecs(wiki_vec, vocab, token_set[:4])))\n",
    "right_neighbour_matrix = np.c_[right_vec_list]\n",
    "\n",
    "neighbour_4_matrix = np.concatenate([left_neighbour_matrix, right_neighbour_matrix], axis=1)\n",
    " \n",
    "ins_del_4_sum_neighbour_matrix = np.concatenate([left_neighbour_matrix, ins_del_sum_matrix, right_neighbour_matrix], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del left_vec_list\n",
    "del right_vec_list\n",
    "del right_neighbour_matrix\n",
    "del left_neighbour_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhoutte analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for number of neighbours=4. Only considering the neighbour vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels=[]\n",
    "cluster_sizes = [20, 50, 90, 120]\n",
    "\n",
    "for n in cluster_sizes:\n",
    "    km = KMeans(n_clusters= n, n_jobs=3)\n",
    "    clusters = km.fit(neighbour_4_matrix)\n",
    "    cluster_labels.append( clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhoutee_s = [silhouette_samples(neighbour_4_matrix, labels) for labels in cluster_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_var = [ np.var(s) for s in silhoutee_s]\n",
    "s_max = [ np.max(s) for s in silhoutee_s]\n",
    "s_median = [ np.median(s) for s in silhoutee_s]\n",
    "s_mean = [np.mean(s) for s in silhoutee_s]\n",
    "s_iqr = [stats.iqr(s) for s in silhoutee_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cluster_sizes\n",
    "plt.plot(x,s_max, \"ro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, s_mean, \"co\")\n",
    "plt.plot(x, s_iqr, \"ro\")\n",
    "plt.plot(x, s_var, \"bo\")\n",
    "plt.plot(x, s_median, \"go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for number of neighbours=10. Only considering the neighbour vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels=[]\n",
    "cluster_sizes = [20, 50, 90, 120]\n",
    "for n in cluster_sizes:\n",
    "    km = KMeans(n_clusters= n, n_jobs=3)\n",
    "    clusters = km.fit(neighbour_10_matrix)\n",
    "    cluster_labels.append( clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhoutee_s = [silhouette_samples(neighbour_10_matrix, labels) for labels in cluster_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_var = [ np.var(s) for s in silhoutee_s]\n",
    "s_max = [ np.max(s) for s in silhoutee_s]\n",
    "s_median = [ np.median(s) for s in silhoutee_s]\n",
    "s_mean = [np.mean(s) for s in silhoutee_s]\n",
    "s_iqr = [stats.iqr(s) for s in silhoutee_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cluster_sizes\n",
    "plt.plot(x,s_max, \"ro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, s_mean, \"co\")\n",
    "plt.plot(x, s_iqr, \"ro\")\n",
    "plt.plot(x, s_var, \"bo\")\n",
    "plt.plot(x, s_median, \"go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[np.argsort(silhoutee_s)[-8:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(silhoutee_s)[np.argsort(silhoutee_s)[-8:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "style_dict = {'border': \"2px solid #000\",\n",
    "              \"text-align\": \"justify\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.64 s, sys: 1.35 s, total: 6.99 s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NO_OF_CLUSTERS = 70\n",
    "km = KMeans(n_clusters= NO_OF_CLUSTERS, n_jobs=3)\n",
    "clusters = km.fit(neighbour_4_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_df[\"cluster_4\"] = pd.Series(clusters.labels_, index= change_df.index)\n",
    "change_grouped_by_tokens_4_neigh = change_df.groupby(\"cluster_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "repers_4_neigh = [ change_grouped_by_tokens_4_neigh[[\"left_string\",\"del_string\", \"ins_string\", \"right_string\"]].get_group(i).style.set_properties(**style_dict, axis=None).set_caption(\"group \"+ str(i) ).render() for i in range(NO_OF_CLUSTERS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_html = \" \".join(repers_4_neigh)\n",
    "file_name = article_name + \"_4_neigh_\"+str(NO_OF_CLUSTERS) + \"_clusters.html\"\n",
    "file_path = os.path.join(\"./visualisation\", file_name)\n",
    "with open(file_path, 'wb') as f:\n",
    "    f.write(all_html.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96b672e73af49fbab5bfcc03e34f9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( clusters_html=fixed(repers_4_neigh), group=range(70))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html[group]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster number of neighbour tokens=10, number of clusters =100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.86 s, sys: 1.12 s, total: 4.98 s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NO_OF_CLUSTERS = 100\n",
    "km = KMeans(n_clusters= NO_OF_CLUSTERS, n_jobs=3)\n",
    "clusters = km.fit(neighbour_10_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_df[\"cluster_10\"] = pd.Series(clusters.labels_, index= change_df.index)\n",
    "change_grouped_by_tokens_10_neigh = change_df.groupby(\"cluster_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "repers_10_neigh = [ change_grouped_by_tokens_10_neigh[[\"left_string\",\"del_string\", \"ins_string\", \"right_string\"]].get_group(i).style.set_properties(**style_dict, axis=None).set_caption(\"group \"+ str(i) ).render() for i in range(NO_OF_CLUSTERS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_html = \" \".join(repers_10_neigh)\n",
    "file_name = article_name + \"_10_neigh_\"+str(NO_OF_CLUSTERS) +\"_clusters.html\"\n",
    "file_path = os.path.join(\"./visualisation\", file_name)\n",
    "with open(file_path, 'wb') as f:\n",
    "    f.write(all_html.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= HTML(repers[0])\n",
    "for repr in repers:\n",
    "    display(HTML( \"<br/><br/><br/>\"+repr ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90457af06fde421a921fbe4798644d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( clusters_html=fixed(repers_10_neigh), group=range(100))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html[group]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = list(range(20))\n",
    "id_str = [\"group \"+str(i) for i in id]\n",
    "drop_down = list(zip(id_str, id))\n",
    "# interact(display_clusters, clusters_html=fixed(repers), group= drop_down);\n",
    "interact(display_clusters, clusters_html=fixed(repers),  group= drop_down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 9.92 s, total: 21.9 s\n",
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NO_OF_CLUSTERS = 100\n",
    "km = KMeans(n_clusters= NO_OF_CLUSTERS, n_jobs=3)\n",
    "clusters = km.fit(ins_del_4_sum_neighbour_matrix)\n",
    "change_df[\"cluster_4_full\"] = pd.Series(clusters.labels_, index= change_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_grouped_by_tokens_4_full = change_df.groupby(\"cluster_4_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "repers_4_full = [ change_grouped_by_tokens_4_full[[\"left_string\",\"del_string\", \"ins_string\", \"right_string\"]].get_group(i).style.set_properties(**style_dict, axis=None).set_caption(\"group \"+ str(i) ).render() for i in range(NO_OF_CLUSTERS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_html = \" \".join(repers_4_full)\n",
    "file_name = article_name + \"_4_full_\"+str(NO_OF_CLUSTERS) + \"_clusters.html\"\n",
    "file_path = os.path.join(\"./visualisation\", file_name)\n",
    "with open(file_path, 'wb') as f:\n",
    "    f.write(all_html.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a9822e93de41fba775c4f2da95a2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( clusters_html=fixed(repers_4_full), group=range(100))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html[group]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the cluster with change object\n",
    "###### TO-DO: save change object and cluster seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/wrod2vec/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->['ins_tokens', 'del_tokens', 'left_neigh', 'right_neigh', 'left_token', 'right_token', 'left_string', 'ins_string', 'del_string', 'right_string']]\n",
      "\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "cluster_dir = \"../data/clusters/\"\n",
    "file_name = article_name + \"_cluster.h5\"\n",
    "full_file_path = os.path.join(cluster_dir, file_name)\n",
    "with pd.HDFStore(full_file_path, 'w') as store:\n",
    "    store.put(\"change_object\", change_df, table=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking\n",
    "###### Ranking clustered groups on following parameters.\n",
    "1. Size of clusters\n",
    "2. No of unique editors is clusters\n",
    "3. Total period of cluster. i.e difference between start and end date.\n",
    "4. Median length of edited token in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_size = change_grouped_by_tokens.size().sort_values()\n",
    "rank_by_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_uniq_editor = change_grouped_by_tokens[\"editor_s\"].nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_period = change_grouped_by_tokens[\"timestamp\"].apply(lambda x: x.max() - x.min()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_rate = change_grouped_by_tokens[\"time_gap\"].apply(lambda x: x.mean()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_token_length = (change_grouped_by_tokens[\"ins_token_len\"].median() + change_grouped_by_tokens[\"del_token_len\"].median()).sort_values()\n",
    "rank_by_token_length = ranks_by_token_length /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log10(cluster_ranks_by_size), rank_by_uniq_editor)\n",
    "plt.scatter(np.log10(cluster_ranks_by_size), rank_by_token_length)\n",
    "plt.scatter(np.log10(cluster_ranks_by_size), np.log10(pd.to_numeric(rank_by_period)))\n",
    "plt.scatter(np.log10(cluster_ranks_by_size), np.log10(pd.to_numeric(rank_by_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_grouped_by_tokens.get_group(cluster_ranks_by_period.index.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_grouped_by_tokens.get_group(cluster_ranks_by_period.index.tolist()[0])[\"del_string\"].str.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "silhoutee_s = []\n",
    "for n in range(2,48,2):\n",
    "    km = KMeans(n_clusters= n, n_jobs=3)\n",
    "    clusters = km.fit(ins_del_sum_neighbour_matrix)\n",
    "    cluster_s = pd.Series(clusters.labels_, index= change_df.index)\n",
    "    silhoutee_s.append(silhouette_score(change_matrix, cluster_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2,48,2)\n",
    "plt.plot(x,silhoutee_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[np.argsort(silhoutee_s)[-8:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(silhoutee_s)[np.argsort(silhoutee_s)[-8:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km = KMeans(n_clusters= 12, n_jobs=3)\n",
    "clusters = km.fit(ins_del_sum_neighbour_matrix)\n",
    "cluster_s = pd.Series(clusters.labels_, index= change_df.index)\n",
    "change_df[\"cluster\"] = cluster_s\n",
    "change_grouped_by_sum = change_df.groupby(\"cluster\")\n",
    "change_grouped_by_sum.size().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_size = change_grouped_by_sum.size().sort_values()\n",
    "rank_by_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_uniq_editor = change_grouped_by_sum[\"editor_s\"].nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_period = change_grouped_by_sum[\"timestamp\"].apply(lambda x: x.max() - x.min()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_rate = change_grouped_by_sum[\"time_gap\"].apply(lambda x: x.mean()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_token_length = (change_grouped_by_sum[\"ins_token_len\"].median() + change_grouped_by_sum[\"del_token_len\"].median()).sort_values()\n",
    "rank_by_token_length = ranks_by_token_length /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log10(cluster_ranks_by_size), rank_by_uniq_editor)\n",
    "plt.scatter(np.log10(cluster_ranks_by_size), rank_by_token_length)\n",
    "plt.scatter(np.log10(cluster_ranks_by_size), np.log10(pd.to_numeric(rank_by_period)))\n",
    "plt.scatter(np.log10(cluster_ranks_by_size), np.log10(pd.to_numeric(rank_by_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_grouped_by_sum.get_group(9)[[\"del_string\", \"ins_string\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
