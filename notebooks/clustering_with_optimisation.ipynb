{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "from sklearn.metrics import  silhouette_score, silhouette_samples\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading the change object and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_name = \"Violence_against_Muslims_in_India\"\n",
    "change_object_dir =  \"../data/change objects/\"\n",
    "\n",
    "change_object_file_name = f\"{article_name}_vec.npz\"\n",
    "filename =  f\"{article_name}_change.h5\"\n",
    "\n",
    "change_object_file = os.path.join(change_object_dir, filename)\n",
    "\n",
    "change_vector_dir = \"../data/change_vector_optimised/\"\n",
    "change_vector_file = os.path.join(change_vector_dir, change_object_file_name)\n",
    "\n",
    "content_dir = \"../data/content/\"\n",
    "len_file = article_name + \"_rev_len.h5\"\n",
    "len_file_path = os.path.join(content_dir, len_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 100\n",
    "def plot_freq(gap_freq, left_context_freq, right_context_freq, timestamp, relative_position, number=100):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3,figsize=(35, 20))\n",
    "        \n",
    "    axs[0].barh( left_context_freq.index[:count][::-1], left_context_freq.values[:count][::-1])\n",
    "    axs[0].set_title(\" frequency plot of top 100 words in left context\")\n",
    "    axs[0].set_xlabel(\"frequency\")\n",
    "    axs[0].set_ylabel(\"unique words in left context \")\n",
    "    \n",
    "    axs[1].barh( gap_freq.index[:count][::-1], gap_freq.values[:count][::-1])\n",
    "    axs[1].set_title(\" frequency plot of top 100 words in gap\")\n",
    "    axs[1].set_xlabel(\"frequency\")\n",
    "    axs[1].set_ylabel(\"unique words in gap \")\n",
    "    \n",
    "    axs[2].barh( right_context_freq.index[:count][::-1], right_context_freq.values[:count][::-1])\n",
    "    axs[2].set_title(\" frequency plot of top 100 words in right context\")\n",
    "    axs[2].set_xlabel(\"frequency\")\n",
    "    axs[2].set_ylabel(\"unique words in right context \")\n",
    "    \n",
    "    fig2, ax = plt.subplots(nrows=1, ncols=1,figsize=(35, 20))\n",
    "    ax.scatter( np.arange(relative_position.shape[0])+1, relative_position, c=\"red\",marker=\"D\", label = \"relative position with respect to timestamp\")\n",
    "    ax.set_title(\"Time scale invariant Plot of timestamp with relative position\")\n",
    "    ax.set_xlabel(\"Position with respect to time\")\n",
    "    ax.set_ylabel(\"relative position \")\n",
    "    ax.set_xticklabels(timestamp)\n",
    "    ax.legend()\n",
    "#     axs[3].set_xscale(\"log\")\n",
    "#     axs[3].set_yscale(\"log\")\n",
    "\n",
    "\n",
    "    return fig\n",
    "# _= plot_freq(edited_tokens_freq_per_group.loc[1], \n",
    "#             left_context_freq_per_group.loc[1], \n",
    "#             right_context_freq_per_group.loc[1],\n",
    "#             change_grouped_by_tokens[\"timestamp\"].get_group(2).values,\n",
    "#             change_grouped_by_tokens[\"relative_position\"].get_group(2).values\n",
    "#             )\n",
    "\n",
    "def display_article_content(index, change_html_series, edited_tokens_freq_per_group, left_context_freq_per_group, right_context_freq_per_group, change_grouped_by_tokens, out):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        \n",
    "    change_html = change_html_series.loc[index]\n",
    "    _ = plot_freq(edited_tokens_freq_per_group.loc[index], \n",
    "            left_context_freq_per_group.loc[index], \n",
    "            right_context_freq_per_group.loc[index],\n",
    "            change_grouped_by_tokens[\"timestamp\"].get_group(index).values,\n",
    "            change_grouped_by_tokens[\"relative_position\"].get_group(index).values)\n",
    "    with out:\n",
    "#         display(change_html)\n",
    "        display(f\"Word length distribution for {index}\")\n",
    "#         display(fig)\n",
    "        display(HTML(change_html))\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 332 ms, sys: 52 ms, total: 384 ms\n",
      "Wall time: 383 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if os.path.exists(change_object_file):\n",
    "    with pd.HDFStore(change_object_file, 'r') as store:\n",
    "        change_object_dataframe = store.get(\"data\")\n",
    "else:\n",
    "    print(\"file do not exist\")\n",
    "rev_len_df = pd.read_hdf(len_file_path, key = \"rev_len\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make left, ins and delete string for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_object_dataframe[\"left_string\"] = change_object_dataframe[\"left_token\"].str.join(\" \")\n",
    "change_object_dataframe[\"ins_string\"] = change_object_dataframe[\"ins_tokens\"].str.join(\" \")\n",
    "change_object_dataframe[\"del_string\"] = change_object_dataframe[\"del_tokens\"].str.join(\" \")\n",
    "change_object_dataframe[\"right_string\"] = change_object_dataframe[\"right_token\"].str.join(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove bigger change object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3181, 18)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_object_dataframe[\"ins_length\"]= change_object_dataframe[\"ins_tokens\"].apply(lambda x: len(x))\n",
    "change_object_dataframe[\"del_length\"]= change_object_dataframe[\"del_tokens\"].apply(lambda x: len(x))\n",
    "\n",
    "optimised_change_object_mask = ((change_object_dataframe[\"ins_length\"] <= 20 ) & (change_object_dataframe[\"del_length\"] <= 20))\n",
    "\n",
    "change_object_dataframe = change_object_dataframe[optimised_change_object_mask]\n",
    "\n",
    "change_object_dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Vectors of change object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 400 ms, sys: 1 s, total: 1.4 s\n",
      "Wall time: 8.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(change_vector_file, \"rb\") as file:\n",
    "    arrays_dict = np.load(file)\n",
    "    neighbour_10_matrix = arrays_dict[\"neighbour_10\"]\n",
    "    ins_del_10_sum_neighbour_matrix = arrays_dict[\"ins_del_10_sum_neighbour\"]\n",
    "    neighbour_4_matrix = arrays_dict[\"neighbour_4\"]\n",
    "    ins_del_4_sum_neighbour_matrix = arrays_dict[\"ins_del_4_sum_neighbour\"]\n",
    "    weighted_neighbour_matrix = arrays_dict[\"weighted_neighbour_matrix\"]\n",
    "    ins_del_weighted_neighbour_matrix = arrays_dict[\"ins_del_weighted_neighbour_matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3933, 600)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimised_change_object[\"ins_token_len\"]=optimised_change_object[\"ins_tokens\"].str.len()\n",
    "# optimised_change_object[\"del_token_len\"]=optimised_change_object[\"del_tokens\"].str.len()\n",
    "weighted_neighbour_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove vectors whose change object has been removed due to optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3181, 600)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_ins_del_4_sum_neighbour_matrix = ins_del_4_sum_neighbour_matrix[optimised_change_object_mask,:]\n",
    "optimised_ins_del_weighted_neighbour_matrix = ins_del_weighted_neighbour_matrix[optimised_change_object_mask,:]\n",
    "optimised_neighbour_4_matrix = neighbour_4_matrix[optimised_change_object_mask,:]\n",
    "optimised_ins_del_10_sum_neighbour_matrix = ins_del_10_sum_neighbour_matrix[optimised_change_object_mask,:]\n",
    "optimised_neighbour_10_matrix = neighbour_10_matrix[optimised_change_object_mask,:]\n",
    "optimised_weighted_neighbour_matrix  =  weighted_neighbour_matrix[optimised_change_object_mask,:]\n",
    "optimised_weighted_neighbour_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_style =     [\n",
    "    {'selector': 'table', 'props': [('border', \"6px double #696969\")]},\n",
    "    {'selector': 'th', 'props': [('border', \"2px solid #D3D3D3\"), (\"font-size\", \"100%\")]},\n",
    "    {\"selector\":\".data\", \"props\":[(\"text-align\", \"justify\"), ('border', \"1px solid #000\"), ('margin', '4px 24px 4px 24px' ), (\"font-size\", \"8pt\")]}\n",
    "] \n",
    "\n",
    "deleted_token_style = {\"color\":\"red\", \"font-weight\": \"bold\",\"font-size\": \"100px\"}\n",
    "inserted_token_style = {\"color\":\"blue\", \"font-weight\": \"bold\",\"font-size\": \"100px\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "style_dict = {'border': \"2px solid #000\",\n",
    "              \"text-align\": \"justify\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clustering using DB scan\n",
    "#### clustering weighted neighbour using dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.29 s, sys: 4 ms, total: 8.3 s\n",
      "Wall time: 8.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "clusters = DBSCAN(eps=0.5, min_samples=4).fit(optimised_weighted_neighbour_matrix)\n",
    "change_object_dataframe[\"dbscan_weighted_neighbour\"] = pd.Series(clusters.labels_, index= change_object_dataframe.index)\n",
    "repers_weighted = change_object_dataframe.groupby(\"dbscan_weighted_neighbour\")[[\"left_string\", \"del_string\", \"ins_string\", \"right_string\"]].apply(lambda x: x.style.render())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6873a6c4d584478898a071f2e256bc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( clusters_html=fixed(repers_weighted), group=range(change_object_dataframe.groupby(\"dbscan_weighted_neighbour\").ngroups))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html.iloc[group]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All weighted vectors weighted_left + gap + weighted_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 12 ms, total: 10.8 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "clusters = DBSCAN(eps=0.4, min_samples=4).fit(optimised_ins_del_weighted_neighbour_matrix)\n",
    "change_object_dataframe[\"dbscan_weighted_all\"] = pd.Series(clusters.labels_, index= change_object_dataframe.index)\n",
    "repers_weigh_all = change_object_dataframe.groupby(\"dbscan_weighted_all\")[[\"left_string\", \"del_string\", \"ins_string\", \"right_string\"]].apply(lambda x: x.style.render())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff750907432645e69d969cb76b092633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( clusters_html=fixed(repers_weigh_all), group=range(change_object_dataframe.groupby(\"dbscan_weighted_all\").ngroups))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html.iloc[group]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  neghbours of size 4 vectors clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 7.49 s, total: 1min 44s\n",
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "NO_OF_CLUSTERS = 70\n",
    "km = KMeans(n_clusters= NO_OF_CLUSTERS, n_jobs=3, n_init=50)\n",
    "clusters = km.fit(optimised_neighbour_4_matrix)\n",
    "\n",
    "change_object_dataframe[\"cluster_4\"] = pd.Series(clusters.labels_, index= change_object_dataframe.index)\n",
    "\n",
    "repers_4_neigh = change_object_dataframe.groupby(\"cluster_4\")[[\"left_string\", \"del_string\", \"ins_string\", \"right_string\"]].apply(lambda x: x.style.render())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3427f4bbb5e341a893feb22ace207324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( clusters_html=fixed(repers_4_neigh), group=range(change_object_dataframe.groupby(\"cluster_4\").ngroups))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html.iloc[group]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster number of neighbour tokens=10, number of clusters =100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.9 s, sys: 1.66 s, total: 26.5 s\n",
      "Wall time: 6.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NO_OF_CLUSTERS = 100\n",
    "km = KMeans(n_clusters= NO_OF_CLUSTERS, n_jobs=3)\n",
    "clusters_10 = km.fit(optimised_neighbour_10_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_object_dataframe[\"cluster_10\"] = pd.Series(clusters_10.labels_, index= change_object_dataframe.index)\n",
    "change_grouped_by_tokens_10_neigh = change_object_dataframe.groupby(\"cluster_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "repers_10_full_neigh = change_grouped_by_tokens_10_neigh[[\"left_string\", \"del_string\", \"ins_string\", \"right_string\"]].apply(lambda x: x.style.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b82423d2114543a6361d5f711486f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( clusters_html=fixed(repers_10_full_neigh), group=range(change_grouped_by_tokens_10_neigh.ngroups))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html.iloc[group]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering with vectors concatinated vectors average of 4 right and left neighbours and average of inserted and deleted tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.8 s, sys: 2.75 s, total: 40.5 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NO_OF_CLUSTERS = 100\n",
    "km = KMeans(n_clusters= NO_OF_CLUSTERS, n_jobs=3)\n",
    "\n",
    "clusters_4_full = km.fit(optimised_ins_del_4_sum_neighbour_matrix)\n",
    "change_object_dataframe[\"cluster_4_full\"] = pd.Series(clusters_4_full.labels_, index= change_object_dataframe.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_grouped_by_tokens_4_full = change_object_dataframe.groupby(\"cluster_4_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "repers_4_full_neigh = change_grouped_by_tokens_4_full[[\"left_string\", \"del_string\", \"ins_string\", \"right_string\"]].apply(lambda x: x.style.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15d830b55e6416ebebac99761b818c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( clusters_html=fixed(repers_4_full_neigh), group=range(change_grouped_by_tokens_4_full.ngroups))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html.iloc[group]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted neghbours vectors clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 38s, sys: 7.35 s, total: 1min 45s\n",
      "Wall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NO_OF_CLUSTERS = 70\n",
    "km = KMeans(n_clusters= NO_OF_CLUSTERS, n_jobs=3, n_init=50)\n",
    "clusters_neighbour = km.fit(optimised_weighted_neighbour_matrix)\n",
    "\n",
    "change_object_dataframe[\"cluster_weighted_neighbour\"] = pd.Series(clusters_neighbour.labels_, index= change_object_dataframe.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b79f3ab37e435cb6c69d8725425bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "repers_weighted_neigh = change_object_dataframe.groupby(\"cluster_weighted_neighbour\")[[\"left_string\", \"del_string\", \"ins_string\", \"right_string\"]].apply(lambda x: x.style.render())\n",
    "@interact( clusters_html=fixed(repers_4_neigh), group=range(change_object_dataframe.groupby(\"cluster_weighted_neighbour\").ngroups))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html.iloc[group]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering with vectors concatinated vectors weighted average of 4 right and left neighbours and average of inserted and deleted tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.6 s, sys: 2.6 s, total: 40.2 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NO_OF_CLUSTERS = 100\n",
    "km = KMeans(n_clusters= NO_OF_CLUSTERS, n_jobs=3)\n",
    "clusters_4_full = km.fit(optimised_ins_del_weighted_neighbour_matrix)\n",
    "change_object_dataframe[\"cluster_4_weighted\"] = pd.Series(clusters_4_full.labels_, index= change_object_dataframe.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_grouped_by_tokens_4_weighted = change_object_dataframe.groupby(\"cluster_4_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "repers_4_weighted = change_grouped_by_tokens_4_weighted[[\"left_string\", \"del_string\", \"ins_string\", \"right_string\"]].apply(lambda x: x.style.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6045ba475842eaae1cabe8224e1e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( clusters_html=fixed(repers_4_weighted), group=range(change_grouped_by_tokens_4_weighted.ngroups))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html.iloc[group]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the cluster with change object\n",
    "###### TO-DO: save change object and cluster seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dir = \"../data/clusters/\"\n",
    "\n",
    "file_name = article_name + \"_optimised_cluster.h5\"\n",
    "full_file_path = os.path.join(cluster_dir, file_name)\n",
    "with pd.HDFStore(full_file_path, 'w') as store:\n",
    "    store.put(\"cluster\", change_object_dataframe[[\"dbscan_weighted_neighbour\",\"dbscan_weighted_all\",\"cluster_weighted_neighbour\",'cluster_4', 'cluster_10',\n",
    "       'cluster_4_full', 'cluster_4_weighted']], table=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking\n",
    "###### Ranking clustered groups on following parameters.\n",
    "1. Size of clusters\n",
    "2. No of unique editors is clusters\n",
    "3. Total period of cluster. i.e difference between start and end date.\n",
    "4. Median length of edited token in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_size = change_grouped_by_tokens_4_weighted.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_uniq_editor = change_object_dataframe.reset_index().groupby(\"cluster_4_weighted\")[\"editor\"].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_period = change_object_dataframe.reset_index().groupby(\"cluster_4_weighted\")[\"timestamp\"].apply(lambda x: x.max() - x.min()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_rate = change_object_dataframe.reset_index().groupby(\"cluster_4_weighted\")[\"timegap\"].apply(lambda x: x.mean()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_token_length = (change_grouped_by_tokens_4_weighted[\"ins_token_len\"].median() + change_grouped_by_tokens_4_weighted[\"del_token_len\"].median()).sort_values()\n",
    "rank_by_token_length = rank_by_token_length /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_tokens_per_group = change_grouped_by_tokens_4_weighted[\"ins_tokens\"].apply(lambda x: pd.Series(np.concatenate(x.values,axis=0)))\n",
    "del_tokens_per_group = change_grouped_by_tokens_4_weighted[\"del_tokens\"].apply(lambda x: pd.Series(np.concatenate(x.values,axis=0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
