{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bykau_dir = \"../data/bykau_change_object/\"\n",
    "pre_evaluation_dir = \"../data/pre_evaluation/\"\n",
    "list_of_articles=pd.read_csv(\"../conflicted_article.csv\")[\"articles\"].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_change_vectors(article_name, change_vector_dir = \"../data/change_vector/\"):\n",
    "    change_vec_filename = f\"{article_name}.npz\"\n",
    "    change_vector_file = os.path.join(change_vector_dir, change_vec_filename)\n",
    "    vectors ={}\n",
    "    with open(change_vector_file, \"rb\") as file:\n",
    "        arrays_dict = np.load(file)\n",
    "        vectors[\"clean_notweighted_4\"] = arrays_dict[\"4_clean_not_weighted\"]\n",
    "        vectors[\"clean_notweighted_10\"] = arrays_dict[\"10_clean_not_weighted\"] \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing article name Berlin_Wall\n",
      "-0.00503339860959055\n",
      "0.004765580841912523\n",
      "processing article name E_(mathematical_constant)\n",
      "0.03149563342326151\n",
      "0.04503417079771628\n",
      "processing article name Yugoslavia\n",
      "0.020458177588963417\n",
      "0.038378385683354145\n",
      "processing article name Censorship\n",
      "-0.008166700499307279\n",
      "-0.00838450964434865\n",
      "processing article name Mama's_Family\n",
      "0.10619340608277333\n",
      "0.09128037993339409\n",
      "processing article name Human_cloning\n",
      "-0.050395350561397344\n",
      "-0.038387719021942726\n"
     ]
    }
   ],
   "source": [
    "for article_name in list_of_articles[1:-6]:\n",
    "    print(f\"processing article name {article_name}\")\n",
    "    filename =  f\"{article_name}_change.h5\"\n",
    "    bykau_cluster_file = os.path.join(bykau_dir, filename)\n",
    "    with pd.HDFStore(bykau_cluster_file, 'r') as store:\n",
    "        bykau_cluster = store.get(\"data\")  \n",
    "    vectors = read_change_vectors(article_name)\n",
    "    clusters_4 = DBSCAN(eps=1.5,min_samples=5, ).fit(vectors[\"clean_notweighted_4\"]).labels_\n",
    "    clusters_10 = DBSCAN(eps=1.5,min_samples=5, ).fit(vectors[\"clean_notweighted_10\"]).labels_\n",
    "    print(adjusted_rand_score(bykau_cluster,clusters_4))\n",
    "    print(adjusted_rand_score(bykau_cluster,clusters_10))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
