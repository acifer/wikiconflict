{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(\"../\")\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from scripts.wiki import Wiki,Revision\n",
    "from sklearn.metrics import  silhouette_score, silhouette_samples\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vecs(wiki_vec, vocab, tokens):\n",
    "    in_vocab_tokens = set(tokens) & vocab\n",
    "    if in_vocab_tokens:\n",
    "#         return wiki_vec[in_vocab_tokens].sum(axis=0, keepdims=True) / len(in_vocab_tokens) \n",
    "        return np.average(wiki_vec[in_vocab_tokens], axis=0)\n",
    "\n",
    "\n",
    "    else:\n",
    "        return np.zeros( wiki_vec.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### reading the change object and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.4 s, sys: 21 s, total: 1min 20s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "article_name = \"Truth\"\n",
    "change_object_dir =  \"../data/change objects/\"\n",
    "filename = article_name + \".pkl\"\n",
    "filepath = os.path.join(change_object_dir, filename)\n",
    "if os.path.exists(filepath):\n",
    "    with open(filepath, \"rb\") as file:\n",
    "        wiki = pickle.load(file)\n",
    "else:\n",
    "    print(\"file do not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 s, sys: 16 ms, total: 1.41 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "change_objects = []\n",
    "wiki.revisions.iloc[:-1].apply(lambda revision: change_objects.append(revision.neighbour))\n",
    "change_index = [ rev.id for rev in  wiki.revisions[1:].tolist()]\n",
    "change_df = pd.concat(change_objects, sort=False, keys=change_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_s = pd.to_datetime([ rev.timestamp for rev in  wiki.revisions.values.ravel().tolist()])\n",
    "time_gap = pd.to_timedelta(timestamp_s[1:]-timestamp_s[:-1])\n",
    "editor_s = [ rev.id for rev in  wiki.revisions.tolist()]\n",
    "index = list(zip(*[timestamp_s.tolist()[1:], time_gap, editor_s[1:]]))\n",
    "# change_df = pd.concat(change_objects, sort=False, keys=index, names=[\"timestamp\", \"timegap\", \"editor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(change_objects)):\n",
    "#     change_objects[i][\"timestamp\"] = timestamp_s[i+1]\n",
    "#     change_objects[i][\"time_gap\"] = time_gap[i]\n",
    "#     change_objects[i][\"editor_s\"] = editor_s[i+1]\n",
    "# change_df = pd.concat(change_objects, sort=False, keys=wiki.revisions[:-1].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make left, ins and delete string for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_df[\"left_string\"] = change_df[\"left_token\"].str.join(\" \")\n",
    "change_df[\"ins_string\"] = change_df[\"ins_tokens\"].str.join(\" \")\n",
    "change_df[\"del_string\"] = change_df[\"del_tokens\"].str.join(\" \")\n",
    "change_df[\"right_string\"] = change_df[\"right_token\"].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_df[\"ins_token_len\"]=change_df[\"ins_tokens\"].str.len()\n",
    "change_df[\"del_token_len\"]=change_df[\"del_tokens\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ins_tokens</th>\n",
       "      <th>del_tokens</th>\n",
       "      <th>left_neigh</th>\n",
       "      <th>right_neigh</th>\n",
       "      <th>left_token</th>\n",
       "      <th>right_token</th>\n",
       "      <th>left_string</th>\n",
       "      <th>ins_string</th>\n",
       "      <th>del_string</th>\n",
       "      <th>right_string</th>\n",
       "      <th>ins_token_len</th>\n",
       "      <th>del_token_len</th>\n",
       "      <th>cluster_4</th>\n",
       "      <th>cluster_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">286907</th>\n",
       "      <th>0</th>\n",
       "      <td>(-, -, -, -)</td>\n",
       "      <td>()</td>\n",
       "      <td>slice(0, 3, None)</td>\n",
       "      <td>slice(1, 32, None)</td>\n",
       "      <td>({st@rt}, &lt;, the)</td>\n",
       "      <td>(&lt;, the, following, is, a, portion, of, larrys...</td>\n",
       "      <td>{st@rt} &lt; the</td>\n",
       "      <td>- - - -</td>\n",
       "      <td></td>\n",
       "      <td>&lt; the following is a portion of larrystext , w...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(foregoing,)</td>\n",
       "      <td>()</td>\n",
       "      <td>slice(0, 8, None)</td>\n",
       "      <td>slice(4, 35, None)</td>\n",
       "      <td>({st@rt}, &lt;, the, following, is, a, portion, of)</td>\n",
       "      <td>(is, a, portion, of, larrystext, ,, wikificati...</td>\n",
       "      <td>{st@rt} &lt; the following is a portion of</td>\n",
       "      <td>foregoing</td>\n",
       "      <td></td>\n",
       "      <td>is a portion of larrystext , wikification is e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([[, larrys, text, ]], ., if, you, can, do, be...</td>\n",
       "      <td>()</td>\n",
       "      <td>slice(0, 10, None)</td>\n",
       "      <td>slice(9, 40, None)</td>\n",
       "      <td>({st@rt}, &lt;, the, following, is, a, portion, o...</td>\n",
       "      <td>(,, wikification, is, encouraged, &gt;, what, is,...</td>\n",
       "      <td>{st@rt} &lt; the following is a portion of larrys...</td>\n",
       "      <td>[[ larrys text ]] . if you can do better</td>\n",
       "      <td></td>\n",
       "      <td>, wikification is encouraged &gt; what is truth ?...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(you, can, feel, free, to, radically, update, ...</td>\n",
       "      <td>()</td>\n",
       "      <td>slice(4212, 4243, None)</td>\n",
       "      <td>slice(13, 44, None)</td>\n",
       "      <td>(to, rest, content, with, any, sort, of, relat...</td>\n",
       "      <td>(&gt;, what, is, truth, ?, we, ’, ll, look, at, a...</td>\n",
       "      <td>to rest content with any sort of relativism th...</td>\n",
       "      <td>you can feel free to radically update or even ...</td>\n",
       "      <td></td>\n",
       "      <td>&gt; what is truth ? we ’ ll look at a number of ...</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>()</td>\n",
       "      <td>(following,)</td>\n",
       "      <td>slice(0, 3, None)</td>\n",
       "      <td>slice(4, 35, None)</td>\n",
       "      <td>({st@rt}, &lt;, the)</td>\n",
       "      <td>(is, a, portion, of, larrystext, ,, wikificati...</td>\n",
       "      <td>{st@rt} &lt; the</td>\n",
       "      <td></td>\n",
       "      <td>following</td>\n",
       "      <td>is a portion of larrystext , wikification is e...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ins_tokens    del_tokens  \\\n",
       "286907 0                                       (-, -, -, -)            ()   \n",
       "       1                                       (foregoing,)            ()   \n",
       "       2  ([[, larrys, text, ]], ., if, you, can, do, be...            ()   \n",
       "       3  (you, can, feel, free, to, radically, update, ...            ()   \n",
       "       4                                                 ()  (following,)   \n",
       "\n",
       "                       left_neigh          right_neigh  \\\n",
       "286907 0        slice(0, 3, None)   slice(1, 32, None)   \n",
       "       1        slice(0, 8, None)   slice(4, 35, None)   \n",
       "       2       slice(0, 10, None)   slice(9, 40, None)   \n",
       "       3  slice(4212, 4243, None)  slice(13, 44, None)   \n",
       "       4        slice(0, 3, None)   slice(4, 35, None)   \n",
       "\n",
       "                                                 left_token  \\\n",
       "286907 0                                  ({st@rt}, <, the)   \n",
       "       1   ({st@rt}, <, the, following, is, a, portion, of)   \n",
       "       2  ({st@rt}, <, the, following, is, a, portion, o...   \n",
       "       3  (to, rest, content, with, any, sort, of, relat...   \n",
       "       4                                  ({st@rt}, <, the)   \n",
       "\n",
       "                                                right_token  \\\n",
       "286907 0  (<, the, following, is, a, portion, of, larrys...   \n",
       "       1  (is, a, portion, of, larrystext, ,, wikificati...   \n",
       "       2  (,, wikification, is, encouraged, >, what, is,...   \n",
       "       3  (>, what, is, truth, ?, we, ’, ll, look, at, a...   \n",
       "       4  (is, a, portion, of, larrystext, ,, wikificati...   \n",
       "\n",
       "                                                left_string  \\\n",
       "286907 0                                      {st@rt} < the   \n",
       "       1            {st@rt} < the following is a portion of   \n",
       "       2  {st@rt} < the following is a portion of larrys...   \n",
       "       3  to rest content with any sort of relativism th...   \n",
       "       4                                      {st@rt} < the   \n",
       "\n",
       "                                                 ins_string del_string  \\\n",
       "286907 0                                            - - - -              \n",
       "       1                                          foregoing              \n",
       "       2           [[ larrys text ]] . if you can do better              \n",
       "       3  you can feel free to radically update or even ...              \n",
       "       4                                                     following   \n",
       "\n",
       "                                               right_string  ins_token_len  \\\n",
       "286907 0  < the following is a portion of larrystext , w...              4   \n",
       "       1  is a portion of larrystext , wikification is e...              1   \n",
       "       2  , wikification is encouraged > what is truth ?...             10   \n",
       "       3  > what is truth ? we ’ ll look at a number of ...             37   \n",
       "       4  is a portion of larrystext , wikification is e...              0   \n",
       "\n",
       "          del_token_len  cluster_4  cluster_10  \n",
       "286907 0              0         71          71  \n",
       "       1              0         78          78  \n",
       "       2              0         78          78  \n",
       "       3              0         11          11  \n",
       "       4              1          9           9  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Vector from change object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 2s, sys: 17.3 s, total: 8min 20s\n",
      "Wall time: 9min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "wiki_vec = KeyedVectors.load_word2vec_format('../../wordvectors/wiki.en.vec', binary=False, limit=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(wiki_vec.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.26 s, sys: 672 ms, total: 8.94 s\n",
      "Wall time: 7.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ins_vec_list = []\n",
    "change_df[\"ins_tokens\"].apply(lambda token_set: ins_vec_list.append(get_word_vecs(wiki_vec, vocab, token_set)))\n",
    "ins_matrix = np.c_[ins_vec_list]\n",
    "\n",
    "del_vec_list = []\n",
    "change_df[\"del_tokens\"].apply(lambda token_set: del_vec_list.append(get_word_vecs(wiki_vec, vocab, token_set)))\n",
    "del_matrix = np.c_[del_vec_list]\n",
    "ins_del_sum_matrix = (ins_matrix + del_matrix)/2\n",
    "\n",
    "del ins_vec_list\n",
    "del del_vec_list\n",
    "del ins_matrix\n",
    "del del_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.82 s, sys: 760 ms, total: 9.58 s\n",
      "Wall time: 8.39 s\n",
      "Parser   : 380 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "left_vec_list = []\n",
    "change_df[\"left_token\"].apply(lambda token_set: left_vec_list.append(get_word_vecs(wiki_vec, vocab, token_set[-10:])))\n",
    "left_neighbour_matrix = np.c_[left_vec_list]\n",
    "\n",
    "right_vec_list = []\n",
    "change_df[\"right_token\"].apply(lambda token_set: right_vec_list.append(get_word_vecs(wiki_vec, vocab, token_set[:10])))\n",
    "right_neighbour_matrix = np.c_[right_vec_list]\n",
    "\n",
    "neighbour_10_matrix = np.concatenate([ left_neighbour_matrix, right_neighbour_matrix], axis=1)\n",
    "\n",
    "ins_del_10_sum_neighbour_matrix = np.concatenate([left_neighbour_matrix, ins_del_sum_matrix, right_neighbour_matrix], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.08 s, sys: 872 ms, total: 7.95 s\n",
      "Wall time: 6.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "left_vec_list = []\n",
    "change_df[\"left_token\"].apply(lambda token_set: left_vec_list.append(get_word_vecs(wiki_vec, vocab, token_set[-4:])))\n",
    "left_neighbour_matrix = np.c_[left_vec_list]\n",
    "\n",
    "right_vec_list = []\n",
    "change_df[\"right_token\"].apply(lambda token_set: right_vec_list.append(get_word_vecs(wiki_vec, vocab, token_set[:4])))\n",
    "right_neighbour_matrix = np.c_[right_vec_list]\n",
    "\n",
    "neighbour_4_matrix = np.concatenate([left_neighbour_matrix, right_neighbour_matrix], axis=1)\n",
    " \n",
    "ins_del_4_sum_neighbour_matrix = np.concatenate([left_neighbour_matrix, ins_del_sum_matrix, right_neighbour_matrix], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del left_vec_list\n",
    "del right_vec_list\n",
    "del right_neighbour_matrix\n",
    "del left_neighbour_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhoutte analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for number of neighbours=4. Only considering the neighbour vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels=[]\n",
    "cluster_sizes = [20, 50, 90, 120]\n",
    "\n",
    "for n in cluster_sizes:\n",
    "    km = KMeans(n_clusters= n, n_jobs=3)\n",
    "    clusters = km.fit(neighbour_4_matrix)\n",
    "    cluster_labels.append( clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-282-b605a6867598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msilhoutee_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msilhouette_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbour_4_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcluster_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-282-b605a6867598>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msilhoutee_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msilhouette_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbour_4_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcluster_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/wrod2vec/lib/python3.6/site-packages/sklearn/metrics/cluster/unsupervised.py\u001b[0m in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# label.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcurr_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mcurrent_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# Leave out current sample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "silhoutee_s = [silhouette_samples(neighbour_4_matrix, labels) for labels in cluster_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_var = [ np.var(s) for s in silhoutee_s]\n",
    "s_max = [ np.max(s) for s in silhoutee_s]\n",
    "s_median = [ np.median(s) for s in silhoutee_s]\n",
    "s_mean = [np.mean(s) for s in silhoutee_s]\n",
    "s_iqr = [stats.iqr(s) for s in silhoutee_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cluster_sizes\n",
    "plt.plot(x,s_max, \"ro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, s_mean, \"co\")\n",
    "plt.plot(x, s_iqr, \"ro\")\n",
    "plt.plot(x, s_var, \"bo\")\n",
    "plt.plot(x, s_median, \"go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for number of neighbours=10. Only considering the neighbour vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels=[]\n",
    "cluster_sizes = [20, 50, 90, 120]\n",
    "for n in cluster_sizes:\n",
    "    km = KMeans(n_clusters= n, n_jobs=3)\n",
    "    clusters = km.fit(neighbour_10_matrix)\n",
    "    cluster_labels.append( clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhoutee_s = [silhouette_samples(neighbour_10_matrix, labels) for labels in cluster_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_var = [ np.var(s) for s in silhoutee_s]\n",
    "s_max = [ np.max(s) for s in silhoutee_s]\n",
    "s_median = [ np.median(s) for s in silhoutee_s]\n",
    "s_mean = [np.mean(s) for s in silhoutee_s]\n",
    "s_iqr = [stats.iqr(s) for s in silhoutee_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cluster_sizes\n",
    "plt.plot(x,s_max, \"ro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, s_mean, \"co\")\n",
    "plt.plot(x, s_iqr, \"ro\")\n",
    "plt.plot(x, s_var, \"bo\")\n",
    "plt.plot(x, s_median, \"go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[np.argsort(silhoutee_s)[-8:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(silhoutee_s)[np.argsort(silhoutee_s)[-8:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dict = {'border': \"2px solid #000\",\n",
    "              \"text-align\": \"justify\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.64 s, sys: 1.35 s, total: 6.99 s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NO_OF_CLUSTERS = 70\n",
    "km = KMeans(n_clusters= NO_OF_CLUSTERS, n_jobs=3)\n",
    "clusters = km.fit(neighbour_4_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_df[\"cluster_4\"] = pd.Series(clusters.labels_, index= change_df.index)\n",
    "change_grouped_by_tokens_4_neigh = change_df.groupby(\"cluster_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "repers_4_neigh = [ change_grouped_by_tokens_4_neigh[[\"left_string\",\"del_string\", \"ins_string\", \"right_string\"]].get_group(i).style.set_properties(**style_dict, axis=None).set_caption(\"group \"+ str(i) ).render() for i in range(NO_OF_CLUSTERS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_html = \" \".join(repers_4_neigh)\n",
    "file_name = article_name + \"_4_neigh_\"+str(NO_OF_CLUSTERS) + \"_clusters.html\"\n",
    "file_path = os.path.join(\"./visualisation\", file_name)\n",
    "with open(file_path, 'wb') as f:\n",
    "    f.write(all_html.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96b672e73af49fbab5bfcc03e34f9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( clusters_html=fixed(repers_4_neigh), group=range(70))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html[group]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster number of neighbour tokens=10, number of clusters =100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.86 s, sys: 1.12 s, total: 4.98 s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NO_OF_CLUSTERS = 100\n",
    "km = KMeans(n_clusters= NO_OF_CLUSTERS, n_jobs=3)\n",
    "clusters = km.fit(neighbour_10_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_df[\"cluster_10\"] = pd.Series(clusters.labels_, index= change_df.index)\n",
    "change_grouped_by_tokens_10_neigh = change_df.groupby(\"cluster_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "repers_10_neigh = [ change_grouped_by_tokens_10_neigh[[\"left_string\",\"del_string\", \"ins_string\", \"right_string\"]].get_group(i).style.set_properties(**style_dict, axis=None).set_caption(\"group \"+ str(i) ).render() for i in range(NO_OF_CLUSTERS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_html = \" \".join(repers_10_neigh)\n",
    "file_name = article_name + \"_10_neigh_\"+str(NO_OF_CLUSTERS) +\"_clusters.html\"\n",
    "file_path = os.path.join(\"./visualisation\", file_name)\n",
    "with open(file_path, 'wb') as f:\n",
    "    f.write(all_html.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= HTML(repers[0])\n",
    "for repr in repers:\n",
    "    display(HTML( \"<br/><br/><br/>\"+repr ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90457af06fde421a921fbe4798644d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( clusters_html=fixed(repers_10_neigh), group=range(100))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html[group]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = list(range(20))\n",
    "id_str = [\"group \"+str(i) for i in id]\n",
    "drop_down = list(zip(id_str, id))\n",
    "# interact(display_clusters, clusters_html=fixed(repers), group= drop_down);\n",
    "interact(display_clusters, clusters_html=fixed(repers),  group= drop_down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 9.92 s, total: 21.9 s\n",
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NO_OF_CLUSTERS = 100\n",
    "km = KMeans(n_clusters= NO_OF_CLUSTERS, n_jobs=3)\n",
    "clusters = km.fit(ins_del_4_sum_neighbour_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_df[\"cluster_4_full\"] = pd.Series(clusters.labels_, index= change_df.index)\n",
    "change_grouped_by_tokens_4_full = change_df.groupby(\"cluster_4_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "repers_4_full = [ change_grouped_by_tokens_4_full[[\"left_string\",\"del_string\", \"ins_string\", \"right_string\"]].get_group(i).style.set_properties(**style_dict, axis=None).set_caption(\"group \"+ str(i) ).render() for i in range(NO_OF_CLUSTERS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_html = \" \".join(repers_4_full)\n",
    "file_name = article_name + \"_4_full_\"+str(NO_OF_CLUSTERS) + \"_clusters.html\"\n",
    "file_path = os.path.join(\"./visualisation\", file_name)\n",
    "with open(file_path, 'wb') as f:\n",
    "    f.write(all_html.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a9822e93de41fba775c4f2da95a2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='group', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( clusters_html=fixed(repers_4_full), group=range(100))\n",
    "def display_clusters(clusters_html, group):\n",
    "     return display(HTML(clusters_html[group]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the cluster with change object\n",
    "###### TO-DO: save change object and cluster seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/wrod2vec/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->['ins_tokens', 'del_tokens', 'left_neigh', 'right_neigh', 'left_token', 'right_token', 'left_string', 'ins_string', 'del_string', 'right_string']]\n",
      "\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "cluster_dir = \"../data/clusters/\"\n",
    "file_name = article_name + \"_cluster.h5\"\n",
    "full_file_path = os.path.join(cluster_dir, file_name)\n",
    "with pd.HDFStore(full_file_path, 'w') as store:\n",
    "    store.put(\"change_object\", change_df, table=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking\n",
    "###### Ranking clustered groups on following parameters.\n",
    "1. Size of clusters\n",
    "2. No of unique editors is clusters\n",
    "3. Total period of cluster. i.e difference between start and end date.\n",
    "4. Median length of edited token in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_size = change_grouped_by_tokens.size().sort_values()\n",
    "rank_by_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_uniq_editor = change_grouped_by_tokens[\"editor_s\"].nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_period = change_grouped_by_tokens[\"timestamp\"].apply(lambda x: x.max() - x.min()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_rate = change_grouped_by_tokens[\"time_gap\"].apply(lambda x: x.mean()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_token_length = (change_grouped_by_tokens[\"ins_token_len\"].median() + change_grouped_by_tokens[\"del_token_len\"].median()).sort_values()\n",
    "rank_by_token_length = ranks_by_token_length /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log10(cluster_ranks_by_size), rank_by_uniq_editor)\n",
    "plt.scatter(np.log10(cluster_ranks_by_size), rank_by_token_length)\n",
    "plt.scatter(np.log10(cluster_ranks_by_size), np.log10(pd.to_numeric(rank_by_period)))\n",
    "plt.scatter(np.log10(cluster_ranks_by_size), np.log10(pd.to_numeric(rank_by_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_grouped_by_tokens.get_group(cluster_ranks_by_period.index.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_grouped_by_tokens.get_group(cluster_ranks_by_period.index.tolist()[0])[\"del_string\"].str.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "silhoutee_s = []\n",
    "for n in range(2,48,2):\n",
    "    km = KMeans(n_clusters= n, n_jobs=3)\n",
    "    clusters = km.fit(ins_del_sum_neighbour_matrix)\n",
    "    cluster_s = pd.Series(clusters.labels_, index= change_df.index)\n",
    "    silhoutee_s.append(silhouette_score(change_matrix, cluster_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2,48,2)\n",
    "plt.plot(x,silhoutee_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[np.argsort(silhoutee_s)[-8:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(silhoutee_s)[np.argsort(silhoutee_s)[-8:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km = KMeans(n_clusters= 12, n_jobs=3)\n",
    "clusters = km.fit(ins_del_sum_neighbour_matrix)\n",
    "cluster_s = pd.Series(clusters.labels_, index= change_df.index)\n",
    "change_df[\"cluster\"] = cluster_s\n",
    "change_grouped_by_sum = change_df.groupby(\"cluster\")\n",
    "change_grouped_by_sum.size().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_size = change_grouped_by_sum.size().sort_values()\n",
    "rank_by_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_uniq_editor = change_grouped_by_sum[\"editor_s\"].nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_period = change_grouped_by_sum[\"timestamp\"].apply(lambda x: x.max() - x.min()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_rate = change_grouped_by_sum[\"time_gap\"].apply(lambda x: x.mean()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_token_length = (change_grouped_by_sum[\"ins_token_len\"].median() + change_grouped_by_sum[\"del_token_len\"].median()).sort_values()\n",
    "rank_by_token_length = ranks_by_token_length /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log10(cluster_ranks_by_size), rank_by_uniq_editor)\n",
    "plt.scatter(np.log10(cluster_ranks_by_size), rank_by_token_length)\n",
    "plt.scatter(np.log10(cluster_ranks_by_size), np.log10(pd.to_numeric(rank_by_period)))\n",
    "plt.scatter(np.log10(cluster_ranks_by_size), np.log10(pd.to_numeric(rank_by_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_grouped_by_sum.get_group(9)[[\"del_string\", \"ins_string\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
